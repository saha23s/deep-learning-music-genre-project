# Genre Classification

Team Members: Sulagna

Instructions on how to run the code:
1. Download the GTZAN dataset from the following link: https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification
2. Extract the dataset and place it in the 'Data' folder in the same directory as the notebook "MusicGenreClassification_Model_Creation.ipynb"
3. Run the code cells in the notebook to extract features from raw audio files and train the models.
4. The code cells are divided into two parts: Feature Extraction from Scratch and Feature Extraction Using Pre-trained VGGish Model.
5. The Feature Extraction from Scratch part extracts features from raw audio files and trains the models using LSTM, CNN, and Transformer architectures.
6. The Feature Extraction Using Pre-trained VGGish Model part extracts features using the pre-trained VGGish model and trains the models using LSTM, CNN, and Transformer architectures.
7. The results of the models are displayed at the end of each part.

Abstract:

Our project proposes the implementation of a deep learning model for music genre classification. The task of music genre classification, as defined by Tzanetakis and Cook, aims to accurately predict the genre of a given piece of music. Such a task could enhance various music-related applications, including music recommendation systems and search engines, which rely on precise genre labeling.

Accurate genre classification could also assist in music analysis and understanding the characteristics of different music genres. The project might employ deep learning methods, which have shown promise in automatically learning features and patterns in audio data. These methods could potentially improve the accuracy of genre classification.

However, the specific deep learning techniques and architectures to be used will be determined as the project progresses, taking into consideration the latest advancements and best practices in the field.

References:

Tzanetakis, G., & Cook, P. (2002). Musical genre classification of audio signals. IEEE Transactions on speech and audio processing.
Scaringella, N., Zoia, G., & Mlynek, D. (2006). Automatic genre classification of music content: a survey. IEEE Signal Processing Magazine.
Choi, K., Fazekas, G., Sandler, M., & Cho, K. (2017). Convolutional recurrent neural networks for music classification. 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).
Dieleman, S., & Schrauwen, B. (2014). End-to-end learning for music audio. 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).

Initial Data Pre-processing Code from GTZAN Genre Dataset: uploaded on Guthub (On Progress)


